{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birdsong Pytorch Baseline: ResNeSt50-fast (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import yaml\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import resnest.torch as resnest_torch\n",
    "\n",
    "import pytorch_pfn_extras as ppe\n",
    "from pytorch_pfn_extras.training import extensions as ppe_extensions\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.autonotebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import catalyst\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from catalyst.dl.callbacks import MixupCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n",
      "Is fp16: True\n",
      "Number of cores CPU: 12\n",
      "GPU: GeForce GTX 1050 Ti\n",
      "Batch size: 128\n",
      "Total device memory: 4042\n"
     ]
    }
   ],
   "source": [
    "from utils.settings import settings\n",
    "NUM_CORES, BS = settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd()#.parent\n",
    "INPUT_ROOT = ROOT / \"data\"\n",
    "RAW_DATA = INPUT_ROOT / \"birdsong-recognition\"\n",
    "TRAIN_AUDIO_DIR = INPUT_ROOT / \"train_audio\"\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test_audio\"\n",
    "TRAIN_RESAMPLED_DIR = INPUT_ROOT / \"train_audio_resampled\"\n",
    "OUTPUT_ROOT = ROOT / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/dmi/5F9CFB7847A8B8FE/kaggle/birdsong')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(RAW_DATA / \"train.csv\")\n",
    "train = pd.read_csv(INPUT_ROOT / \"train_mod.csv\")[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not TEST_AUDIO_DIR.exists():\n",
    "#     TEST_AUDIO_DIR = INPUT_ROOT / \"birdcall_check\" / \"test_audio\"\n",
    "#     test = pd.read_csv(INPUT_ROOT / \"birdcall_check\" / \"test.csv\")\n",
    "# else:\n",
    "#     test = pd.read_csv(RAW_DATA / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import get_loaders\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = next(iter(loaders[\"train\"]))[0][0].permute(1, 2, 0)\n",
    "# plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def get_resnest(model='resnest50_fast_1s1x64d', pretrained=True, n_classes=264):\n",
    "    model = getattr(resnest_torch, model)(pretrained=pretrained)\n",
    "    del model.fc\n",
    "    # # use the same head as the baseline notebook.\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, n_classes))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/zhanghang1989/ResNeSt/archive/master.zip\" to /home/dmi/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['resnest101',\n",
       " 'resnest200',\n",
       " 'resnest269',\n",
       " 'resnest50',\n",
       " 'resnest50_fast_1s1x64d',\n",
       " 'resnest50_fast_1s2x40d',\n",
       " 'resnest50_fast_1s4x24d',\n",
       " 'resnest50_fast_2s1x64d',\n",
       " 'resnest50_fast_2s2x40d',\n",
       " 'resnest50_fast_4s1x64d',\n",
       " 'resnest50_fast_4s2x40d']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_resnest('resnest101') #'resnest200'\n",
    "# model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(model: object, head_lr: float = 0.001, reduce: float = 0.3):\n",
    "\n",
    "    lr = [\n",
    "        {'params': model.conv1.parameters(), 'lr': head_lr * reduce * reduce * reduce}, \n",
    "        {'params': model.layer1.parameters(), 'lr': head_lr * reduce * reduce}, \n",
    "        {'params': model.layer2.parameters(), 'lr': head_lr * reduce * reduce}, \n",
    "        {'params': model.layer3.parameters(), 'lr': head_lr * reduce}, \n",
    "        {'params': model.layer4.parameters(), 'lr': head_lr * reduce}, \n",
    "        {'params': model.fc.parameters(), 'lr': head_lr}]\n",
    "\n",
    "    return lr  \n",
    "\n",
    "# get_lr(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] train: 80, val: 20\n"
     ]
    }
   ],
   "source": [
    "from utils.albusound import train_transforms\n",
    "loaders = collections.OrderedDict()\n",
    "loaders[\"train\"], loaders[\"valid\"] = get_loaders(0, BS=2, waveform_transforms=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/home/dmi/anaconda3/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so: undefined symbol: THPVariableClass')\n",
      "1/5 * Epoch (train): 100% 40/40 [00:09<00:00,  4.25it/s, f1_score=1.000, loss=0.000e+00]\n",
      "1/5 * Epoch (valid): 100% 10/10 [00:01<00:00,  8.23it/s, f1_score=1.000, loss=0.000e+00]\n",
      "[2020-09-01 18:48:11,025] \n",
      "1/5 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
      "1/5 * Epoch 1 (train): f1_score=0.8860 | loss=0.0433\n",
      "1/5 * Epoch 1 (valid): f1_score=0.9872 | loss=0.0001\n",
      "2/5 * Epoch (train): 100% 40/40 [00:08<00:00,  4.87it/s, f1_score=1.000, loss=0.000e+00]\n",
      "2/5 * Epoch (valid): 100% 10/10 [00:01<00:00,  8.17it/s, f1_score=1.000, loss=0.000e+00]\n",
      "[2020-09-01 18:48:29,397] \n",
      "2/5 * Epoch 2 (_base): lr=0.0010 | momentum=0.9000\n",
      "2/5 * Epoch 2 (train): f1_score=1.0000 | loss=0.000e+00\n",
      "2/5 * Epoch 2 (valid): f1_score=1.0000 | loss=0.000e+00\n",
      "3/5 * Epoch (train): 100% 40/40 [00:08<00:00,  4.79it/s, f1_score=1.000, loss=0.000e+00]\n",
      "3/5 * Epoch (valid): 100% 10/10 [00:01<00:00,  7.58it/s, f1_score=1.000, loss=0.000e+00]\n",
      "[2020-09-01 18:48:45,314] \n",
      "3/5 * Epoch 3 (_base): lr=0.0010 | momentum=0.9000\n",
      "3/5 * Epoch 3 (train): f1_score=1.0000 | loss=0.000e+00\n",
      "3/5 * Epoch 3 (valid): f1_score=0.9933 | loss=5.397e-05\n",
      "4/5 * Epoch (train): 100% 40/40 [00:08<00:00,  4.64it/s, f1_score=1.000, loss=0.000e+00]\n",
      "4/5 * Epoch (valid): 100% 10/10 [00:01<00:00,  6.62it/s, f1_score=1.000, loss=0.000e+00]\n",
      "[2020-09-01 18:49:02,028] \n",
      "4/5 * Epoch 4 (_base): lr=0.0010 | momentum=0.9000\n",
      "4/5 * Epoch 4 (train): f1_score=1.0000 | loss=0.000e+00\n",
      "4/5 * Epoch 4 (valid): f1_score=1.0000 | loss=0.000e+00\n",
      "5/5 * Epoch (train): 100% 40/40 [00:08<00:00,  4.56it/s, f1_score=1.000, loss=0.000e+00]\n",
      "5/5 * Epoch (valid): 100% 10/10 [00:01<00:00,  6.76it/s, f1_score=1.000, loss=0.000e+00]\n",
      "[2020-09-01 18:49:19,077] \n",
      "5/5 * Epoch 5 (_base): lr=0.0008 | momentum=0.9000\n",
      "5/5 * Epoch 5 (train): f1_score=1.0000 | loss=0.000e+00\n",
      "5/5 * Epoch 5 (valid): f1_score=1.0000 | loss=2.935e-10\n",
      "Top best models:\n",
      "/media/dmi/5F9CFB7847A8B8FE/kaggle/birdsong/.logs0/checkpoints/train.1.pth\t0.0001\n"
     ]
    }
   ],
   "source": [
    "#set_seed(settings[\"globals\"][\"seed\"])\n",
    "device = catalyst.utils.get_device()\n",
    "output_dir = OUTPUT_ROOT\n",
    "fold = 0\n",
    "# # # get model\n",
    "model = get_resnest()\n",
    "model = model.to(device)\n",
    "\n",
    "lr = 0.001 # get_lr_seresnext(model, 0.01, 0.8)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.75, patience=2)\n",
    "\n",
    "logdir = f\"{ROOT}/.logs{fold}\"\n",
    "device = catalyst.utils.get_device()\n",
    "\n",
    "runner = SupervisedRunner(device=device, model=model)\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "runner.train(\n",
    "model=model,\n",
    "criterion=criterion,\n",
    "optimizer=optimizer,\n",
    "scheduler=scheduler,\n",
    "loaders=loaders,\n",
    "callbacks=[\n",
    "        F1ScoreCallback(prefix=\"f1_score\"),\n",
    "        #MixupCallback(alpha=0.4)\n",
    "        ],\n",
    "logdir=logdir,\n",
    "num_epochs=5,\n",
    "#main_metric=\"total\",\n",
    "minimize_metric=False,\n",
    "# for FP16. It uses the variable from the very first cell\n",
    "# fp16=True,\n",
    "# for external monitoring tools, like Alchemy\n",
    "#monitoring_params=monitoring_params,\n",
    "verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loaders[\"valid\"]))\n",
    "weight_path = '/media/dmi/5F9CFB7847A8B8FE/kaggle/birdsong/.logs0/checkpoints/best.pth'\n",
    "model_ = get_resnest()\n",
    "state_dict = torch.load(weight_path, map_location=device)\n",
    "model_.load_state_dict(state_dict['model_state_dict'])\n",
    "model_.to(device)\n",
    "model_.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 ms, sys: 0 ns, total: 20.9 ms\n",
      "Wall time: 19.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 103.6954, -111.7115, -111.3646, -113.4016, -109.4264, -119.0708,\n",
       "         -113.7141, -119.9767, -105.4297, -123.9350, -115.9076, -107.7744,\n",
       "         -108.8389, -114.1867, -115.0496, -112.8139, -118.1462, -113.5535,\n",
       "         -114.4292, -109.8800, -113.2666, -121.7823, -112.0840, -114.3512,\n",
       "         -116.8399, -108.1066, -120.2018, -111.8183, -113.0793, -112.0995,\n",
       "         -109.1594, -113.2400, -120.9752, -123.5482, -126.6694, -123.8388,\n",
       "         -115.5321, -123.5138, -110.7690, -120.7488, -122.2058, -111.1512,\n",
       "         -113.3404, -123.0019, -118.4223, -116.0455, -108.9969, -118.7995,\n",
       "         -116.4718, -111.9320, -114.0347, -112.6292, -103.0237, -111.0363,\n",
       "         -106.6555, -118.9390, -114.5587, -113.9174, -113.3249, -114.9006,\n",
       "         -111.3956, -114.3081, -117.2529, -121.9041, -120.6378, -119.9404,\n",
       "         -104.5584, -110.7326, -120.8921, -118.0907, -114.0547, -114.9733,\n",
       "         -108.8574, -110.3351, -117.1495, -112.3753, -120.9414, -119.2530,\n",
       "         -111.3816, -112.7480, -117.0526, -119.0812, -116.1807, -118.2131,\n",
       "         -115.2759, -122.6161, -114.1547, -122.3402, -106.3450, -125.7610,\n",
       "         -110.3652, -113.0198, -111.2936, -112.6630, -104.6429, -122.5355,\n",
       "         -111.4158, -119.0492, -112.7384, -113.4492, -118.3286, -115.8108,\n",
       "         -114.9358, -115.5499, -108.0657, -118.5901, -117.2103, -111.2641,\n",
       "         -106.9676, -105.6454, -116.9741, -116.7504, -111.7784, -110.4828,\n",
       "         -110.9888, -122.4460, -113.7557, -112.6642, -117.6115, -121.1866,\n",
       "         -122.1948, -129.6142, -119.1269, -123.2672, -108.6829, -108.9488,\n",
       "         -115.7928, -119.8973, -109.9663, -112.5363, -113.2799, -123.9700,\n",
       "         -116.0885, -115.1579, -111.7861, -112.6614, -119.2511, -119.2476,\n",
       "         -109.4709, -110.0967, -115.0380, -107.4302, -117.1265, -111.4499,\n",
       "         -120.0320, -114.2128, -108.4256, -112.7157, -107.7652, -113.3283,\n",
       "         -112.3953, -114.2108, -117.2658, -112.5462, -125.6854, -105.5841,\n",
       "         -118.5274, -112.0113, -115.8015, -120.8248, -117.8746, -111.0384,\n",
       "         -109.6733, -115.6834, -111.4905, -121.3676, -121.4533, -116.2771,\n",
       "         -115.5293, -116.7866, -119.1882, -115.3675, -110.6617, -112.6993,\n",
       "         -127.8841, -116.1128, -114.0947, -112.6555, -115.7634, -118.8284,\n",
       "         -115.9935, -113.5313, -115.1029, -113.5605, -104.9341, -121.4183,\n",
       "         -110.6027, -115.4520, -107.2473, -123.2520, -110.7749, -113.7233,\n",
       "         -119.1632, -111.1073, -106.6502, -114.0259, -105.7932, -117.2343,\n",
       "         -109.5791, -114.2744, -107.5978, -125.6393, -118.6595, -125.6372,\n",
       "         -109.9939, -117.9552, -112.2289, -110.7959, -112.4502, -112.7906,\n",
       "         -114.1271, -121.1827, -118.5753, -125.6807, -113.5577, -113.5740,\n",
       "         -120.3278, -116.4871, -113.4458, -117.7686, -119.6309, -126.1546,\n",
       "         -100.1242, -111.5861, -114.0988, -119.8802, -112.2817, -110.5754,\n",
       "         -110.3429, -115.5680, -118.6405, -115.8621, -109.3023, -112.9166,\n",
       "         -112.2432, -111.4176, -119.2249, -115.1057, -111.0051, -127.1914,\n",
       "         -111.6242, -117.7649, -118.0282, -123.4628, -111.6826, -115.9356,\n",
       "         -117.9260, -119.0761, -113.4130, -106.0403, -102.9616, -115.3130,\n",
       "         -111.0784, -102.8350, -127.8627, -117.3979, -104.9154, -113.3684,\n",
       "         -123.6485, -110.8799, -108.3393, -123.7773, -105.1265, -118.1813],\n",
       "        [ 267.6673, -288.3409, -287.4909, -292.6012, -282.5884, -307.3289,\n",
       "         -293.6863, -309.6827, -272.2023, -319.8533, -299.4577, -278.2411,\n",
       "         -281.0408, -294.5324, -296.9657, -291.2349, -305.0009, -293.1143,\n",
       "         -295.5718, -283.7292, -292.1950, -314.2903, -289.0938, -295.1500,\n",
       "         -301.5481, -279.1408, -310.4305, -288.6423, -292.2055, -289.2344,\n",
       "         -281.7932, -292.3308, -312.2378, -318.9231, -326.9393, -319.5021,\n",
       "         -298.0385, -318.9801, -285.8307, -311.6606, -315.4821, -286.7993,\n",
       "         -292.7050, -317.3086, -305.6324, -299.4226, -281.1317, -306.2518,\n",
       "         -300.6480, -288.7540, -294.2404, -290.9646, -265.9077, -286.7415,\n",
       "         -275.2433, -307.0781, -295.6504, -294.0576, -292.5290, -296.6027,\n",
       "         -287.3876, -295.0025, -302.5826, -314.7042, -311.3785, -309.7428,\n",
       "         -269.9070, -286.0524, -311.8951, -304.8358, -294.3006, -296.8204,\n",
       "         -280.8726, -284.7697, -302.4676, -290.1607, -312.2032, -307.6800,\n",
       "         -287.4048, -291.1288, -302.1186, -307.4045, -300.0202, -305.0801,\n",
       "         -297.5673, -316.4995, -294.6711, -315.7998, -274.3436, -324.5185,\n",
       "         -284.9458, -291.3856, -287.1502, -290.9736, -270.1166, -316.0573,\n",
       "         -287.6317, -307.3055, -291.0423, -292.8198, -305.2770, -298.7606,\n",
       "         -296.5022, -298.2408, -278.9795, -306.1247, -302.4189, -287.1845,\n",
       "         -276.1474, -272.7173, -301.7968, -301.0972, -288.4226, -285.0706,\n",
       "         -286.5570, -315.9936, -293.5214, -291.0023, -303.7650, -312.8214,\n",
       "         -315.4207, -334.5951, -307.4220, -318.0813, -280.5335, -281.2785,\n",
       "         -298.7058, -309.5018, -283.8295, -290.6881, -292.5575, -320.0357,\n",
       "         -299.4986, -297.0348, -288.7331, -290.7870, -307.7200, -308.1032,\n",
       "         -282.7764, -284.1778, -296.9159, -277.2136, -302.3563, -287.8601,\n",
       "         -309.7212, -294.7334, -279.7835, -290.8477, -278.2125, -292.7442,\n",
       "         -290.1089, -294.6707, -302.6884, -290.7288, -324.6278, -272.4290,\n",
       "         -305.7703, -289.1315, -299.0887, -311.9479, -304.1684, -286.6633,\n",
       "         -283.1973, -298.5841, -287.8160, -313.0132, -313.7350, -300.1911,\n",
       "         -298.4673, -301.2110, -307.5872, -297.7314, -285.5363, -290.7766,\n",
       "         -330.2963, -299.7495, -294.6278, -290.8077, -298.6761, -306.6023,\n",
       "         -299.4634, -292.8325, -296.9880, -293.1534, -271.0031, -313.3763,\n",
       "         -285.5906, -297.9043, -277.0548, -318.2216, -285.8976, -293.4195,\n",
       "         -307.7651, -286.6399, -275.1442, -294.4485, -273.0893, -302.5789,\n",
       "         -282.8124, -295.1629, -277.7134, -324.3192, -306.2268, -324.2972,\n",
       "         -283.8119, -304.4535, -289.5359, -285.8753, -290.3467, -291.0895,\n",
       "         -294.6174, -312.6640, -305.8797, -324.3257, -292.9665, -293.1737,\n",
       "         -310.5303, -300.8909, -292.7952, -303.9398, -308.8111, -325.5073,\n",
       "         -258.5102, -287.9688, -294.5851, -309.4345, -289.9151, -285.4550,\n",
       "         -284.7157, -298.3006, -306.3604, -298.9439, -281.9814, -291.4812,\n",
       "         -289.5611, -287.5742, -307.8002, -297.3785, -286.6853, -328.3263,\n",
       "         -288.0410, -303.9508, -304.4945, -318.7720, -288.4720, -299.5300,\n",
       "         -304.3526, -307.4206, -292.6879, -273.7604, -265.7943, -297.5307,\n",
       "         -286.6764, -265.3468, -329.9293, -302.8629, -270.7836, -292.6350,\n",
       "         -319.2351, -285.9323, -279.3644, -319.6512, -271.3679, -305.0348]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_(batch[0].cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl.utils import trace\n",
    "runner.trace(model=model, loader=loaders['valid'], device=device, logdir=logdir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trace.load_traced_model(\n",
    "        f\"{logdir}/trace/traced-forward.pth\", \n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 ms, sys: 1.98 ms, total: 316 ms\n",
      "Wall time: 315 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  54.6440,  -58.6450,  -58.4889,  -59.5359,  -57.6162,  -62.2326,\n",
       "          -59.7460,  -62.8181,  -55.5352,  -64.8026,  -60.8743,  -56.7018,\n",
       "          -57.1119,  -59.7730,  -60.4132,  -59.2375,  -62.0670,  -59.6546,\n",
       "          -59.9390,  -57.7122,  -59.5339,  -63.8517,  -58.7750,  -60.0015,\n",
       "          -61.3063,  -56.8712,  -63.1277,  -58.7849,  -59.4385,  -58.8474,\n",
       "          -57.3169,  -59.6150,  -63.3780,  -64.7284,  -66.3006,  -65.0466,\n",
       "          -60.6108,  -64.5835,  -58.0950,  -63.1412,  -64.0844,  -58.4242,\n",
       "          -59.5909,  -64.4159,  -62.2140,  -60.8786,  -57.2271,  -62.2216,\n",
       "          -61.0809,  -58.6868,  -59.8414,  -59.1977,  -54.2146,  -58.3470,\n",
       "          -56.1229,  -62.3063,  -60.1628,  -59.7255,  -59.4520,  -60.2280,\n",
       "          -58.4957,  -59.9447,  -61.4386,  -63.8333,  -63.1749,  -62.8327,\n",
       "          -55.0157,  -58.2557,  -63.2988,  -62.0229,  -59.7733,  -60.3885,\n",
       "          -57.2244,  -57.9879,  -61.3960,  -58.9418,  -63.4301,  -62.4207,\n",
       "          -58.5092,  -59.2979,  -61.2759,  -62.4318,  -61.0044,  -61.8556,\n",
       "          -60.3157,  -64.1583,  -59.9313,  -64.0872,  -55.8675,  -65.8561,\n",
       "          -57.9830,  -59.3514,  -58.4776,  -59.1072,  -55.1036,  -64.1614,\n",
       "          -58.4903,  -62.4596,  -59.2272,  -59.4803,  -62.0169,  -60.8035,\n",
       "          -60.3892,  -60.7753,  -56.8716,  -62.1705,  -61.3625,  -58.4561,\n",
       "          -56.3363,  -55.6346,  -61.4224,  -61.2461,  -58.7355,  -58.0662,\n",
       "          -58.3130,  -64.0889,  -59.7572,  -59.1802,  -61.7652,  -63.4941,\n",
       "          -64.1011,  -67.7406,  -62.3464,  -64.4374,  -57.0882,  -57.3844,\n",
       "          -60.6968,  -62.8323,  -57.8244,  -59.1403,  -59.5838,  -64.9502,\n",
       "          -60.9131,  -60.4397,  -58.8134,  -59.1736,  -62.5456,  -62.5588,\n",
       "          -57.5344,  -57.9106,  -60.4376,  -56.4853,  -61.3720,  -58.6409,\n",
       "          -62.8616,  -59.9577,  -56.9391,  -59.2163,  -56.7314,  -59.4592,\n",
       "          -59.0575,  -59.8657,  -61.5003,  -59.1718,  -65.9011,  -55.5788,\n",
       "          -62.1261,  -58.8262,  -60.8220,  -63.1955,  -61.6977,  -58.3560,\n",
       "          -57.6112,  -60.8349,  -58.5579,  -63.5898,  -63.6723,  -61.2082,\n",
       "          -60.6490,  -61.2107,  -62.4623,  -60.5363,  -58.1588,  -59.1077,\n",
       "          -66.9686,  -60.8635,  -59.8835,  -59.2167,  -60.7327,  -62.3069,\n",
       "          -60.8810,  -59.5182,  -60.3389,  -59.6230,  -55.2163,  -63.6689,\n",
       "          -58.0548,  -60.6506,  -56.3190,  -64.5244,  -58.2561,  -59.7259,\n",
       "          -62.5675,  -58.3953,  -56.1208,  -59.7786,  -55.7054,  -61.5897,\n",
       "          -57.6798,  -60.0074,  -56.6657,  -65.6732,  -62.2295,  -65.7607,\n",
       "          -57.7109,  -61.8837,  -58.9853,  -58.1468,  -59.0319,  -59.3667,\n",
       "          -59.9211,  -63.5159,  -62.0539,  -65.6950,  -59.6586,  -59.6503,\n",
       "          -63.0631,  -61.1499,  -59.6877,  -61.8702,  -62.7199,  -65.9503,\n",
       "          -52.7243,  -58.6363,  -59.8677,  -62.7958,  -58.9883,  -58.0576,\n",
       "          -57.9657,  -60.6968,  -62.2384,  -60.8425,  -57.4565,  -59.3061,\n",
       "          -59.0778,  -58.5413,  -62.5609,  -60.4770,  -58.2356,  -66.5267,\n",
       "          -58.6011,  -61.8033,  -61.8859,  -64.6972,  -58.7522,  -60.9849,\n",
       "          -61.7722,  -62.4623,  -59.5642,  -55.9591,  -54.3637,  -60.6147,\n",
       "          -58.4015,  -54.1320,  -66.8742,  -61.5187,  -55.2130,  -59.4556,\n",
       "          -64.7873,  -58.2653,  -56.9144,  -64.7841,  -55.3397,  -61.9623],\n",
       "        [ 215.9499, -231.7850, -231.1281, -235.1397, -227.5766, -246.1875,\n",
       "         -236.0514, -248.1658, -219.5757, -256.3339, -240.2965, -224.0911,\n",
       "         -225.8193, -236.6005, -238.7323, -234.1572, -245.0856, -235.6224,\n",
       "         -236.9624, -228.0331, -235.3161, -252.3275, -232.2986, -237.2107,\n",
       "         -242.4320, -224.7554, -249.3886, -232.2795, -235.0396, -232.5099,\n",
       "         -226.6834, -235.7857, -250.4741, -255.8679, -262.0583, -257.0959,\n",
       "         -239.5809, -255.1093, -229.4793, -249.6309, -253.3415, -230.8377,\n",
       "         -235.4596, -254.6655, -245.6375, -240.7195, -226.3287, -245.7078,\n",
       "         -241.3856, -231.9895, -236.6228, -233.7996, -214.5478, -230.5430,\n",
       "         -221.8492, -246.1919, -237.7495, -236.3651, -235.0315, -238.1321,\n",
       "         -230.9932, -236.8261, -242.6799, -252.0803, -249.8016, -248.7767,\n",
       "         -217.4921, -230.1388, -250.4025, -245.4242, -236.2989, -238.5279,\n",
       "         -226.3989, -229.1172, -242.6915, -232.9032, -250.6329, -246.6864,\n",
       "         -231.2337, -234.1895, -242.5103, -246.6298, -241.0370, -244.6247,\n",
       "         -238.5694, -253.6900, -236.9541, -253.0136, -220.7991, -260.2313,\n",
       "         -229.1963, -234.6305, -231.2746, -233.6762, -217.9062, -253.6325,\n",
       "         -231.2792, -246.8539, -233.7559, -235.0618, -245.1503, -239.9946,\n",
       "         -238.6021, -240.1197, -224.5503, -245.6339, -242.5639, -231.0444,\n",
       "         -222.5832, -219.8392, -242.6743, -241.9402, -232.1294, -229.4013,\n",
       "         -230.2967, -253.5104, -236.0353, -233.9821, -244.1044, -250.7776,\n",
       "         -253.3201, -268.0259, -246.4146, -254.9016, -225.8461, -226.7706,\n",
       "         -240.2467, -248.4696, -228.4157, -233.7584, -235.4473, -256.8801,\n",
       "         -240.6481, -238.8325, -232.4261, -233.8050, -247.0676, -247.1948,\n",
       "         -227.4412, -228.6920, -238.8722, -223.1876, -242.8083, -231.6332,\n",
       "         -248.4771, -237.1036, -225.0484, -234.0238, -224.2925, -234.8717,\n",
       "         -233.4810, -236.8768, -243.1786, -234.0346, -260.4654, -219.8193,\n",
       "         -245.7185, -232.5322, -240.3795, -249.6510, -243.8428, -230.5201,\n",
       "         -227.5400, -240.2298, -231.2333, -251.3940, -251.4632, -241.5894,\n",
       "         -239.6389, -241.7543, -246.9083, -239.0376, -229.9275, -233.6202,\n",
       "         -264.3493, -240.7345, -236.7107, -233.9005, -240.1223, -246.2388,\n",
       "         -240.3920, -235.4579, -238.3711, -235.5967, -218.2972, -251.5326,\n",
       "         -229.4481, -239.5088, -222.6758, -255.0407, -230.1253, -236.2094,\n",
       "         -247.3538, -230.9696, -221.6541, -236.4505, -220.0388, -243.1274,\n",
       "         -227.8257, -236.9633, -223.7169, -259.5549, -245.8072, -259.6623,\n",
       "         -227.9221, -244.6423, -233.0554, -229.7734, -233.4434, -234.5742,\n",
       "         -236.9255, -250.7908, -245.4777, -259.6667, -235.5497, -235.4527,\n",
       "         -249.1650, -241.2447, -235.8956, -244.5121, -247.7239, -261.0182,\n",
       "         -208.3918, -231.7352, -236.6645, -248.2182, -233.1528, -229.5090,\n",
       "         -229.2149, -239.7781, -245.8523, -240.5831, -226.9382, -234.2422,\n",
       "         -233.5004, -231.6079, -247.2242, -238.9900, -230.1816, -262.8203,\n",
       "         -231.8050, -244.1755, -244.9809, -255.4400, -232.1576, -240.8556,\n",
       "         -243.8715, -246.9190, -235.2074, -221.1700, -214.3653, -239.9752,\n",
       "         -230.8237, -213.8522, -264.0887, -243.0092, -218.3607, -234.9418,\n",
       "         -256.0468, -230.5690, -224.9533, -256.2838, -218.6038, -244.8999]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model(batch[0].cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: невозможно получить доступ к '/kaggle/training_output': Нет такого файла или каталога\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'ls /kaggle/training_output\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-51c6b901c75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ls /kaggle/training_output\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'ls /kaggle/training_output\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls /kaggle/training_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_name in [\"log\",\"loss.png\", \"lr.png\"]:\n",
    "    shutil.copy(output_dir / f_name, f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_json(\"log\")\n",
    "best_epoch = log[\"val/loss\"].idxmin() + 1\n",
    "log.iloc[[best_epoch - 1],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(output_dir / \"snapshot_epoch_{}.pth\".format(best_epoch), \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_model({\n",
    "    'name': settings[\"model\"][\"name\"],\n",
    "    'params': {'pretrained': False, 'n_classes': 264}})\n",
    "state_dict = torch.load('best_model.pth')\n",
    "m.load_state_dict(state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
